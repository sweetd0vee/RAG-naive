{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V5E1",
   "authorship_tag": "ABX9TyOgYC/Ch8MOP+uJKpv6Mrcg"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## RAG"
   ],
   "metadata": {
    "id": "1EDAYFJ4lrom"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**RAG (Retrieval-Augmented Generation)** — это одна из самых популярных и эффективных архитектур для создания интеллектуальных чат-ботов и поисковых систем, работающих с вашими собственными данными.\n",
    "\n",
    "\n",
    "**С RAG:** Вы идете в библиотеку (ваше хранилище данных), находите нужные книги и статьи (этап Retrieval), внимательно их читаете (Augmentation), а затем на основе этой актуальной информации пишете свой доклад (Generation).\n",
    "\n",
    "**RAG — это мост между вашими собственными данными и мощью большой языковой модели.** Он решает главные проблемы \"голых\" LLM (устаревание данных и галлюцинации), заставляя модель работать с проверенной и актуальной информацией. Именно поэтому RAG лежит в основе большинства современных корпоративных AI-решений."
   ],
   "metadata": {
    "id": "YpkyFAqDls9d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Токенизация и чанкование: что это и в чём разница**\n",
    "\n",
    "Обработка длинных текстов всегда начинается с токенизации. **Токенизация — это процесс разделения исходного текста на токены: минимальные смысловые или технические единицы.** Для разных языков и задач токен может быть словом, частью слова, символом или даже байтом."
   ],
   "metadata": {
    "id": "Ox8RKs016ntY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Чтобы языковая модель могла эффективно работать с текстом, токены объединяют в более крупные блоки — **чанки** — фрагменты текста, которые используют как единицы поиска и обработки информации.\n",
    "\n",
    "Обычно чанк совпадает с абзацем, предложением или представляет собой фрагмент фиксированной длины — на практике от ≈ 128 до ≈ 1 000 токенов, в зависимости от используемой модели и специфики задачи: чем больше модель допускает контекст, тем крупнее может быть чанк. Процесс формирования таких блоков называют чанкованием: текст разбивают на чанки либо по смысловым границам, либо по заданному числу токенов, чтобы сохранить связность информации и обеспечить эффективную работу retrieval‑системы и генеративной модели.\n",
    "\n"
   ],
   "metadata": {
    "id": "v9o31ZaU6v2e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Способы токенизации и чанкования**\n",
    "\n",
    "**Существует несколько подходов к токенизации:**\n",
    "\n",
    "\n",
    "**По пробелам (whitespace tokenization):** простейший способ, применяется для языков с чёткой границей между словами.\n",
    "Byte Pair Encoding, WordPiece, Unigram: используются в современных моделях — разбивают слова на подслова или даже отдельные символы для повышения гибкости.\n",
    "\n",
    "**Морфологическая токенизация:** для сложных языков — с учётом грамматики.\n",
    "**Для чанкования:**\n",
    "\n",
    "\n",
    "**Применяют фиксированный размер чанка:** каждая часть содержит одинаковое число токенов.\n",
    "\n",
    "**Делят по смысловым границам:** деление по абзацам, предложениям, заголовкам.\n",
    "Применяют метод с перекрытием (overlap): части текста пересекаются, чтобы не терять смысл на стыках."
   ],
   "metadata": {
    "id": "QTIDM43O7NXr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Путь для коллаба\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive/')\n",
    "# path = '/content/drive/MyDrive/Sberbank/LLMs/RAG/article.pdf'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WP_wUm2wlsdZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1763318769322,
     "user_tz": -180,
     "elapsed": 1909,
     "user": {
      "displayName": "Arina Goloubitskaya",
      "userId": "10232983805718510908"
     }
    },
    "outputId": "010ee371-b55b-4c25-8e0a-2c0977bf547c"
   },
   "execution_count": 115,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "path = '/Users/sweetd0ve/Work/Sberbank/llms/rag/article.pdf'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "# !pip install -r /content/drive/MyDrive/Sberbank/LLMs/RAG/requirements.txt\n",
    "!pip3 install -r requirments.txt"
   ],
   "metadata": {
    "id": "fhpom0Mil2VV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1763318792713,
     "user_tz": -180,
     "elapsed": 5199,
     "user": {
      "displayName": "Arina Goloubitskaya",
      "userId": "10232983805718510908"
     }
    }
   },
   "execution_count": 156,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama  # или другая LLM\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\n",
    "    \"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\"\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "from rag import SimpleRAG"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    # Инициализация\n",
    "    rag = SimpleRAG(path)\n",
    "\n",
    "    # Загрузка документа\n",
    "    rag.load_and_process_document()\n",
    "\n",
    "    # Настройка QA системы\n",
    "    rag.setup_qa_chain(model_name=\"llama2\", search_k=3)\n",
    "\n",
    "    # Вопросы\n",
    "    result = rag.ask_question(\"Какие основные темы обсуждаются в документе?\")\n",
    "\n",
    "    # Поиск похожего контента\n",
    "    similar_docs = rag.search_similar(\"машинное обучение\", k=2)\n",
    "\n",
    "    # Информация о системе\n",
    "    print(rag.get_document_info())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "id": "LNx9LLafnb0q",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1763318468554,
     "user_tz": -180,
     "elapsed": 53,
     "user": {
      "displayName": "Arina Goloubitskaya",
      "userId": "10232983805718510908"
     }
    },
    "outputId": "7c433cd2-203e-421b-be63-74b12924015f"
   },
   "execution_count": 175,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 14:00:17 INFO: Загружаю документ...\n",
      "2025-11-17 14:00:19 INFO: Создано 185 чанков из документа\n",
      "2025-11-17 14:00:19 INFO: Используется 185 валидных чанков\n",
      "2025-11-17 14:00:19 INFO: Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2025-11-17 14:00:21 INFO: Создание векторной базы...\n",
      "2025-11-17 14:00:21 WARNING: Способ 1 не сработал: Could not connect to tenant default_tenant. Are you sure it exists?\n",
      "2025-11-17 14:00:21 INFO: Пробую способ 2...\n",
      "2025-11-17 14:00:27 INFO: Векторная база создана с использованием FAISS\n",
      "2025-11-17 14:00:27 INFO: Цепочка QA успешно настроена\n",
      "2025-11-17 14:00:27 INFO: Вопрос: Какие основные темы обсуждаются в документе?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mТы - помощник, отвечающий на вопросы на основе предоставленного контекста.\n",
      "\n",
      "Контекст:\n",
      "\n",
      "\n",
      "Вопрос: Какие основные темы обсуждаются в документе?\n",
      "\n",
      "Инструкции:\n",
      "1. Ответь строго на основе предоставленного контекста\n",
      "2. Если ответа нет в контексте, скажи \"В предоставленных документах нет информации для ответа на этот вопрос\"\n",
      "3. Будь точным и лаконичным\n",
      "4. Используй маркированные списки если уместно\n",
      "\n",
      "Ответ:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "Ответ: В предоставленных документах нет информации для ответа на этот вопрос. Конечно, я могу предложить основные темы, которые могут быть обсуждаемыми в документе, но без доступа к конкретному документу, я не могу указать конкретные темы.\n",
      "\n",
      "Использованные источники (0):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FAISS' object has no attribute '_collection'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[175], line 21\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28mprint\u001B[39m(rag\u001B[38;5;241m.\u001B[39mget_document_info())\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 21\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[175], line 18\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     15\u001B[0m similar_docs \u001B[38;5;241m=\u001B[39m rag\u001B[38;5;241m.\u001B[39msearch_similar(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mмашинное обучение\u001B[39m\u001B[38;5;124m\"\u001B[39m, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Информация о системе\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mrag\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_document_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Work/Sberbank/llms/rag/rag.py:302\u001B[0m, in \u001B[0;36mSimpleRAG.get_document_info\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mДокументы не загружены\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    301\u001B[0m \u001B[38;5;66;03m# Получение количества документов в коллекции\u001B[39;00m\n\u001B[0;32m--> 302\u001B[0m collection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvectorstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_collection\u001B[49m\n\u001B[1;32m    303\u001B[0m count \u001B[38;5;241m=\u001B[39m collection\u001B[38;5;241m.\u001B[39mcount() \u001B[38;5;28;01mif\u001B[39;00m collection \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument_path\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpdf_path,\n\u001B[1;32m    307\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvector_store\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpersist_directory,\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: count,\n\u001B[1;32m    309\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mЗагружено\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    310\u001B[0m }\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'FAISS' object has no attribute '_collection'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "L6Rj1UYjnbvi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "97C7wbBYnbr4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Ij9QqEMQnboP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "dxTbQUHenbkk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "15vDc8EFnbhG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "cGvbI1nAnbaU"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
